{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers.experimental.preprocessing import IntegerLookup\n",
    "from tensorflow.keras import layers\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "tf.config.threading.set_intra_op_parallelism_threads(16) \n",
    "tf.config.threading.set_inter_op_parallelism_threads(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clean_data = '/Users/rathin/Documents/Projects/mids/W207/W207_movies/data/clean_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Prepocessed Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train, dev, test data\n",
    "train_df = pd.read_csv(path_clean_data + \"cf_train_ratings.csv\", low_memory=False)\n",
    "dev_df = pd.read_csv(path_clean_data + \"cf_dev_ratings.csv\", low_memory=False)\n",
    "test_df = pd.read_csv(path_clean_data + \"cf_test_ratings.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'Unnamed 0' column\n",
    "train_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "dev_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "test_df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>223</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>415</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>648</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1097</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1197</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       4      223     4.0\n",
       "1       4      415     4.0\n",
       "2       4      648     4.0\n",
       "3       4     1097     5.0\n",
       "4       4     1197     4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect train_df\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dev and test evaluation pools\n",
    "f1 = open(path_clean_data + 'dev_evaluation_pools.json',)\n",
    "f2 = open(path_clean_data + 'test_evaluation_pools.json',)\n",
    "dev_evaluation_pools = json.load(f1)\n",
    "test_evaluation_pools = json.load(f2)\n",
    "\n",
    "# Convert key from str to int\n",
    "dev_evaluation_pools = {int(k):v for k,v in dev_evaluation_pools.items()}\n",
    "test_evaluation_pools = {int(k):v for k,v in test_evaluation_pools.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Data for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Movies: 44975 \n",
      "Number of Users: 136362 \n"
     ]
    }
   ],
   "source": [
    "## Get lists of unique movie ids and user ids in the training data\n",
    "unique_movie_ids = np.unique(np.concatenate((np.unique(train_df['movieId']),\n",
    "                                             np.unique(dev_df['movieId']),\n",
    "                                             np.unique(test_df['movieId']))))\n",
    "unique_user_ids = np.unique(train_df['userId'])\n",
    "\n",
    "## Calculate number of movies and users and print\n",
    "num_movies = len(unique_movie_ids)\n",
    "num_users = len(unique_user_ids)\n",
    "print(\"Number of Movies: %i \" % num_movies)\n",
    "print(\"Number of Users: %i \" % num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encode movies and users to be contigous  \n",
    "movie2movie_encoded = {x: i for i, x in enumerate(unique_movie_ids)}\n",
    "movie_encoded2movie = {i: x for i, x in enumerate(unique_movie_ids)}\n",
    "user2user_encoded = {x: i for i, x in enumerate(unique_user_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(unique_user_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>movieEncoded</th>\n",
       "      <th>userEncoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>223</td>\n",
       "      <td>4.0</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>415</td>\n",
       "      <td>4.0</td>\n",
       "      <td>411</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>648</td>\n",
       "      <td>4.0</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1097</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1197</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  movieEncoded  userEncoded\n",
       "0       4      223     4.0           220            0\n",
       "1       4      415     4.0           411            0\n",
       "2       4      648     4.0           640            0\n",
       "3       4     1097     5.0          1075            0\n",
       "4       4     1197     4.0          1172            0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add encoding columns to train, test and dev data\n",
    "train_df[\"movieEncoded\"] = train_df[\"movieId\"].map(movie2movie_encoded)\n",
    "train_df[\"userEncoded\"] = train_df[\"userId\"].map(user2user_encoded)\n",
    "\n",
    "dev_df[\"movieEncoded\"] = dev_df[\"movieId\"].map(movie2movie_encoded)\n",
    "dev_df[\"userEncoded\"] = dev_df[\"userId\"].map(user2user_encoded)\n",
    "\n",
    "test_df[\"movieEncoded\"] = test_df[\"movieId\"].map(movie2movie_encoded)\n",
    "test_df[\"userEncoded\"] = test_df[\"userId\"].map(user2user_encoded)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and Evaluate Deep Learning Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_evaluation_pools(model, evaluation_pools):\n",
    "    '''\n",
    "    Take evaluation pool for each user and sort it based on ratings predicted by a \n",
    "    trained model in descending order of predicted ratings\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : A trained surprise model\n",
    "    evaluation_pools : A dictionary from user to the pool of movies on \n",
    "                       which to evaluate the recommender system \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sorted_evaluation_pools : A dictionary from user to the pool of movies where each \n",
    "                              movie is sorted in descending order of predicted movie \n",
    "                              rating\n",
    "    '''\n",
    "    \n",
    "    # Instantiate output dictionary\n",
    "    sorted_evaluation_pools = {}\n",
    "    \n",
    "    # Loop through each key-value pair in the input dictionary\n",
    "    for user, movie_pool in evaluation_pools.items():\n",
    "        \n",
    "        # Create a dictionary for the predicted rating of each movie in the user's pool\n",
    "        predictions = {}\n",
    "        for movie in movie_pool:\n",
    "            pred = model.predict(user, movie)\n",
    "            predictions[movie] = pred[3]\n",
    "        \n",
    "        # Sort the pool in descending order of predicted ratings\n",
    "        sorted_pool = [k for k, v in sorted(predictions.items(), key=lambda item: item[1], reverse=True)]\n",
    "        \n",
    "        # Add key-value pair of user and sorted evalualtion pool to the output dictionary\n",
    "        sorted_evaluation_pools[user] = sorted_pool\n",
    "\n",
    "    return sorted_evaluation_pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hit_rate_pools(sorted_evaluation_pools, test_df, top_n=10):\n",
    "    '''\n",
    "    Calculate hit rate given a dictionary of sorted evaluation pools and the corrsponding \n",
    "    test data frame. A hit is defined as finding a test movie in the top_n of sorted \n",
    "    evalutation pool of a user\n",
    "    Parameters\n",
    "    ----------\n",
    "    sorted_evaluation_pools : A dictionary from user to the pool of movies where each \n",
    "                              movie is sorted in descending order of predicted movie \n",
    "                              rating\n",
    "    test_df : A dataframe of ratings for movies being tested in the evaluation pools\n",
    "    top_n : The threshold above which a test movies should be found to be called a hit\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    hit_rate : A hit rate across pools\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Start with hits and totals at 0\n",
    "    hits=0\n",
    "    total=0\n",
    "    \n",
    "    # Loop through the each key-value pair in the input dictionary\n",
    "    for user, sorted_pool in sorted_evaluation_pools.items():\n",
    "        \n",
    "        # Filter to test movies for the user\n",
    "        test_movies = test_df[test_df['userId']==user]\n",
    "        \n",
    "        # Find top_n movies from the pool\n",
    "        top_movies = sorted_pool[:top_n]\n",
    "        \n",
    "        # Loop through each test movie\n",
    "        for index, test_movie in test_movies.iterrows():\n",
    "            test_movie_id = test_movie['movieId']\n",
    "            \n",
    "            # If test movie is in top_movies, then add one to hits\n",
    "            if test_movie_id in top_movies:\n",
    "                hits += 1\n",
    "                \n",
    "            # Add one to total for each test movie  \n",
    "            total += 1\n",
    "     \n",
    "    hit_rate = hits/total\n",
    "    return hit_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hit_rate_pools_with_cutoff(sorted_evaluation_pools, test_df, top_n=10, rating_cutoff=0):\n",
    "    '''\n",
    "    Calculate hit rate given a dictionary of sorted evaluation pools and a corresponding \n",
    "    test data frame. A hit is defined as finding a test movie that has a rating greater \n",
    "    than a rating_cutoff in the top_n of sorted evalutation pool of a user.\n",
    "    Parameters\n",
    "    ----------\n",
    "    sorted_evaluation_pools : A dictionary from user to the pool of movies where each \n",
    "                              movie is sorted in descending order of predicted movie \n",
    "                              rating\n",
    "    test_df : A dataframe of ratings for movies being tested in the evaluation pools\n",
    "    top_n : The threshold above which a test movies should be found to be called a hit\n",
    "    rating_cutoff : The threshold rating above which a test movie should be evaluated\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    hit_rate : A hit rate across pools\n",
    "    '''\n",
    "    \n",
    "    # Start with hits and totals at 0\n",
    "    hits=0\n",
    "    total=0\n",
    "    \n",
    "    # Loop through the each key-value pair in the input dictionary\n",
    "    for user, sorted_pool in sorted_evaluation_pools.items():\n",
    "        \n",
    "        # Filter to test movies for the user\n",
    "        test_movies = test_df[test_df['userId']==user]\n",
    "\n",
    "         # Find top_n movies from the pool\n",
    "        top_movies = sorted_pool[:top_n]\n",
    "        \n",
    "        # Loop through each test movie\n",
    "        for index, test_movie in test_movies.iterrows():\n",
    "            test_movie_rating = test_movie['rating']\n",
    "            test_movie_id = test_movie['movieId']\n",
    "            \n",
    "             # If test movie has a rating above rating_cutoff then evaluate\n",
    "            if test_movie_rating >= rating_cutoff:\n",
    "                \n",
    "                # If test movie is in top_movies, then add one to hits\n",
    "                if test_movie_id in top_movies:\n",
    "                    hits += 1\n",
    "                \n",
    "                # Add one to total for each test movie\n",
    "                total += 1\n",
    "\n",
    "    return hits/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Deep Learning Model\n",
    "\n",
    "Source: https://heartbeat.fritz.ai/build-train-and-deploy-a-book-recommender-system-using-keras-tensorflow-js-b96944b936a7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_model(num_movies, num_users, embedding_size=15, d1_size=128):\n",
    "    # Movie input network\n",
    "    input_movies = layers.Input(shape=[1])\n",
    "\n",
    "    # Define movies embedding layer\n",
    "    embed_movies = layers.Embedding(num_movies + 1, embedding_size)(input_movies)\n",
    "    movies_out = layers.Flatten()(embed_movies)\n",
    "\n",
    "    # User input network\n",
    "    input_users = layers.Input(shape=[1])\n",
    "\n",
    "    # Define users embedding layer\n",
    "    embed_users = layers.Embedding(num_users + 1,embedding_size)(input_users)\n",
    "    users_out = keras.layers.Flatten()(embed_users)\n",
    "\n",
    "    # Concatenenate Embeddings\n",
    "    conc_layer = keras.layers.Concatenate()([movies_out, users_out])\n",
    "\n",
    "    # Define Dense Layer                    \n",
    "    x = keras.layers.Dense(d1_size, activation='relu')(conc_layer)\n",
    "\n",
    "    # Define output Layer\n",
    "    x_out = x = keras.layers.Dense(1, activation='relu')(x)\n",
    "\n",
    "    # Define model\n",
    "    model = keras.Model(inputs=[input_movies, input_users], outputs=x_out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 15)        674640      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 15)        2045445     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 15)           0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 15)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 30)           0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          3968        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            129         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 2,724,182\n",
      "Trainable params: 2,724,182\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = embedding_model(num_movies, num_users)\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_1.compile(optimizer=opt, loss='mean_squared_error')\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 14824/372774 [>.............................] - ETA: 1:28:58 - loss: 0.9283"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5dd9d05954b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     validation_data=([dev_df.movieEncoded, dev_df.userEncoded],\n\u001b[0;32m----> 8\u001b[0;31m                      dev_df.rating)\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model_1.fit(\n",
    "    x=[train_df.movieEncoded, train_df.userEncoded],\n",
    "    y=train_df.rating, \n",
    "    batch_size=64, \n",
    "    epochs=5, \n",
    "    verbose=1,\n",
    "    validation_data=([dev_df.movieEncoded, dev_df.userEncoded],\n",
    "                     dev_df.rating)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history[\"loss\"])\n",
    "plt.plot(hist.history[\"val_loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
