{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9533b06-7110-418e-9472-fc5b5117f953",
   "metadata": {},
   "source": [
    "### Step 1: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8394217b-7ec5-47b9-92ab-fc212d6c00a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d7dd9b-c232-4dc4-bba3-f3b3d4576d55",
   "metadata": {},
   "source": [
    "### Step 2: Define working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab05abd0-103d-4964-96ab-b799df715b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw_data = 'C:/users/lbros/documents/mids/w207/final_project/raw_data/'\n",
    "path_clean_data = 'C:/users/lbros/documents/mids/w207/final_project/clean_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826754a3-e66a-490a-9394-c965033b75a2",
   "metadata": {},
   "source": [
    "### Step 3: Load clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af236d2d-65bd-4909-8025-b53a7a472b0b",
   "metadata": {},
   "source": [
    "#### Split ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e3572a-528c-4b60-8958-770842618794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ratings dataframes\n",
    "dev_train = pd.read_csv(path_clean_data + 'dev_train.csv')\n",
    "dev_test = pd.read_csv(path_clean_data + 'dev_test.csv')\n",
    "test_train = pd.read_csv(path_clean_data + 'test_train.csv')\n",
    "test_test = pd.read_csv(path_clean_data + 'test_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9ed7d75-a2e1-414a-a2aa-5b5e6b453a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'Unnamed 0' column\n",
    "dev_train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "dev_test.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "test_train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "test_test.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ecbdef-1d61-4601-8c73-0f34ca00b808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(834600, 3)\n",
      "(5000, 3)\n",
      "(17948251, 3)\n",
      "(107150, 3)\n"
     ]
    }
   ],
   "source": [
    "# print dataframes shapes\n",
    "print(dev_train.shape)\n",
    "print(dev_test.shape)\n",
    "print(test_train.shape)\n",
    "print(test_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db0a4767-136b-4c42-9546-9eccfd51fe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['userId', 'imdb_id', 'rating'], dtype='object')\n",
      "Index(['userId', 'imdb_id', 'rating'], dtype='object')\n",
      "Index(['userId', 'imdb_id', 'rating'], dtype='object')\n",
      "Index(['userId', 'imdb_id', 'rating'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print dataframes columns\n",
    "print(dev_train.columns)\n",
    "print(dev_test.columns)\n",
    "print(test_train.columns)\n",
    "print(test_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6738b2-7106-4798-88ae-ebbc4764507b",
   "metadata": {},
   "source": [
    "#### Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33937f1e-11ba-44b4-815c-348797407cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load movies dataframe\n",
    "movies_df = pd.read_csv(path_clean_data + 'movies_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1b2fc61-5d5b-4357-bf17-24dd9bd8bd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated imdb_id:  546\n"
     ]
    }
   ],
   "source": [
    "# print remaining duplicated movies (if any)\n",
    "print('Number of duplicated imdb_id: ', movies_df[movies_df['imdb_id'].duplicated()].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "808647ff-8f78-46a2-b394-4277819e3af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude remaining imdb_id duplicates\n",
    "movies_df = movies_df[~movies_df['imdb_id'].duplicated(keep='last')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a92f1af8-da50-45bb-b958-cdb87cb47634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set imdb_id as index\n",
    "movies_df.set_index('imdb_id', verify_integrity=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e9a747c-23ff-4d50-9f13-f6f52ce6abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter usable columns\n",
    "movies_df = movies_df.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44fbcf4b-a9ed-4a4e-9fdc-ca6cd56cdd48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29399, 176)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print dataframe shape\n",
    "movies_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e287c09-ab07-476e-b8c1-541cb3fd5899",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['belongs_to_collection', 'budget', 'originally_english', 'overview',\n",
       "       'popularity', 'production_companies', 'production_countries', 'revenue',\n",
       "       'runtime', 'tagline',\n",
       "       ...\n",
       "       'zu', 'canceled', 'in-production', 'planned', 'post-production',\n",
       "       'released', 'rumored', 'cast_names', 'crew_names', 'description'],\n",
       "      dtype='object', length=176)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print dataframe columns\n",
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d973a-0c48-4a18-b8cc-bc6777cd297f",
   "metadata": {},
   "source": [
    "### Step 4: Vectorize text fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8324f1a-c2e8-4b21-964c-7ab672f6d116",
   "metadata": {},
   "source": [
    "#### Start with movie description as a pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c57489ef-2352-4182-840c-d3f7e3646568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each movie was converted into 9506 word tokens.\n"
     ]
    }
   ],
   "source": [
    "# initiatize TfidVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "# fit_transform movie description\n",
    "word_vector = vectorizer.fit_transform(movies_df['description'])\n",
    "# print number of features\n",
    "print('Each movie was converted into {} word tokens.'.format(len(vectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93781965-810d-41a5-a7fb-6f42aef43564",
   "metadata": {},
   "source": [
    "### Step 5: Test and tune hyperparameters for different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f2e761-89a1-4003-bd2d-05d2567eaeb4",
   "metadata": {},
   "source": [
    "#### Define auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1d6e79c9-b640-42ec-9838-e26381c688f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clf(user_id, clf, train_ratings_data=dev_train, test_ratings_data=dev_test, movies_data=movies_df, word_vector=word_vector):\n",
    "    \n",
    "    '''Run a classifier for a single user and return the score'''\n",
    "    \n",
    "    # get movies and ratings from user training data\n",
    "    train_movies = train_ratings_data[train_ratings_data['userId']==user_id]['imdb_id']\n",
    "    train_ratings = train_ratings_data[train_ratings_data['userId']==user_id]['rating']\n",
    "    #print('User {} rated {} movies in training set.'.format(user_id, len(train_movies)))\n",
    "    #print('User {} gave {} positive ratings and {} negative ratings.'.format(user_id, (train_ratings==1).sum(), (train_ratings==0).sum()), '\\n')\n",
    "    \n",
    "    # get movie and rating for hold out user test data\n",
    "    hold_out_movie = test_ratings_data[test_ratings_data['userId']==user_id]['imdb_id']\n",
    "    hold_out_rating = test_ratings_data[test_ratings_data['userId']==user_id]['rating']\n",
    "    #print('User {} rated {} movie in the hold-out set.'.format(user_id, len(hold_out_movie)))\n",
    "    #print('User {} gave a {} rating for the hold-out movie.'.format(user_id, int(hold_out_rating)), '\\n')\n",
    "    \n",
    "    # complement test data with other 99 randomly selected movies\n",
    "    allowed_list = movies_data.loc[~movies_data.index.isin(train_movies.append(hold_out_movie))]\n",
    "    rd_movies = allowed_list.sample(n=99, replace=False).index.to_series()\n",
    "    test_movies = hold_out_movie.append(rd_movies)\n",
    "    \n",
    "    # extract X_train and X_test matrices\n",
    "    X_train = word_vector[[movies_data.index.get_loc(x) for x in train_movies], :]\n",
    "    #print('X_train shape:', X_train.shape)\n",
    "    X_test = word_vector[[movies_data.index.get_loc(x) for x in test_movies], :]\n",
    "    #print('X_test shape:', X_test.shape)\n",
    "    \n",
    "    # extrac y_train vector\n",
    "    y_train = train_ratings.values\n",
    "    #print('y_train shape:', y_train.shape, '\\n')\n",
    "    \n",
    "    # fit training data\n",
    "    clf.fit(X_train, y_train)\n",
    "    # compute probabilities for each class\n",
    "    proba = clf.predict_proba(X_test)\n",
    "    # compute the ranking for class==test_ratings\n",
    "    ranking = np.argsort(proba, axis=0)[:,clf.classes_[clf.classes_==int(hold_out_rating)]]\n",
    "    # apply a positive hit if test example ranked on top-10 in descending order\n",
    "    score = ranking[0] > 89\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "521f4068-08ef-4cd2-9314-0a0f805087f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_rate(user_list, clf, train_ratings_data=dev_train, test_ratings_data=dev_test, movies_data=movies_df, word_vector=word_vector):\n",
    "\n",
    "    '''Compute hit rate across diferent users'''\n",
    "    \n",
    "    hit_list = []\n",
    "    for user_id in user_list:\n",
    "        score = run_clf(user_id, clf=clf, train_ratings_data=train_ratings_data, test_ratings_data=test_ratings_data, \n",
    "                            movies_data=movies_data, word_vector=word_vector)\n",
    "        hit_list.append(bool(score))\n",
    "    return sum(hit_list) / len(hit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a350eb0c-ac9d-48e2-86a2-45ffd856618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_rate_by_rating(user_list, clf, train_ratings_data=dev_train, test_ratings_data=dev_test, movies_data=movies_df, word_vector=word_vector):\n",
    "    \n",
    "    '''Compute hit rate by user rating in the hold out movie'''\n",
    "    \n",
    "    # for different ratings in the hold out movie\n",
    "    ratings = [0, 1]\n",
    "    hit_rate_by_rating = []\n",
    "    for r in ratings:\n",
    "        # define the user_list as the subset of users who gave rate r in the hold out movie\n",
    "        user_list = test_ratings_data[test_ratings_data['rating']==r]['userId']\n",
    "        # compute the hit rate\n",
    "        hit_rate = get_hit_rate(user_list=user_list, clf=clf, train_ratings_data=train_ratings_data, test_ratings_data=test_ratings_data, \n",
    "                                movies_data=movies_df, word_vector=word_vector)\n",
    "        # append hit rate to the hit_rate_by_rating\n",
    "        hit_rate_by_rating.append(hit_rate)\n",
    "        # print results\n",
    "        print('For rating=={} hit rate=={:.3f}'.format(r, hit_rate))\n",
    "    \n",
    "    return hit_rate_by_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a3923ad4-422f-4461-973f-2e3c351ceed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_rate_by_n_ratings(user_list, clf, train_ratings_data=dev_train, test_ratings_data=dev_test, movies_data=movies_df, word_vector=word_vector):\n",
    "    \n",
    "    '''Compute hit rate by number of ratings in the user training set'''\n",
    "    \n",
    "    # split users by number of ratings\n",
    "    bins = [0, 50, 100, 150, 200, 20000]\n",
    "    user_list_by_n_ratings = pd.cut(train_ratings_data.groupby('userId').count()['rating'], bins).reset_index('userId')\n",
    "    intervals = user_list_by_n_ratings['rating'].unique()\n",
    "    # for different intervals of number of ratings\n",
    "    hit_rate_by_n_ratings = []\n",
    "    for i in intervals:\n",
    "        # define the user_list as the subset of users within the interval\n",
    "        user_list = user_list_by_n_ratings[user_list_by_n_ratings['rating']==i]['userId']\n",
    "        # compute the hit rate\n",
    "        hit_rate = get_hit_rate(user_list=user_list, clf=clf, train_ratings_data=train_ratings_data, test_ratings_data=test_ratings_data, \n",
    "                                movies_data=movies_df, word_vector=word_vector)\n",
    "        # append hit rate to the hit_rate_by_n_ratings\n",
    "        hit_rate_by_n_ratings.append(hit_rate)\n",
    "        # print results\n",
    "        print('For interval=={} hit rate=={:.3f}'.format(i, hit_rate))\n",
    "        \n",
    "    return hit_rate_by_n_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079dc5de-ee05-4a58-9d54-fa578fb82cd8",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6bbda4ad-a337-429a-9826-feb3676c968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define user_list | limiting to first 500 users to speed up simulations\n",
    "user_list = dev_train['userId'].unique()[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c39cd46b-d104-408f-9298-7a9c5371b89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k== 5 hit rate==0.132\n",
      "For k==10 hit rate==0.138\n",
      "For k==15 hit rate==0.116\n",
      "For k==20 hit rate==0.102\n",
      "For k==25 hit rate==0.134\n"
     ]
    }
   ],
   "source": [
    "# define range for k (n_neighbors) parameter\n",
    "param_range = [5, 10, 15, 20, 25]\n",
    "# for different values of parameter k (n_beighbors)\n",
    "hit_rate_list = []\n",
    "for param in param_range:\n",
    "    # initialize classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=param)\n",
    "    # compute the hit rate\n",
    "    hit_rate = get_hit_rate(user_list, clf=knn)\n",
    "    # append hit rate to the hit_rate_list\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    # print results\n",
    "    print('For k=={:2} hit rate=={:.3f}'.format(param, hit_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d844681-01ae-4a04-9ee3-c8032325f46f",
   "metadata": {},
   "source": [
    "Parameter **n_neighbors (k) will be set as 10**\n",
    "\n",
    "**Hit rate of 13.2%** slighly above 10% baseline of a random ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e3585109-9a1e-4bc2-bada-258ff43e9a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rating==0 hit rate==0.118\n",
      "For rating==1 hit rate==0.125\n"
     ]
    }
   ],
   "source": [
    "# evalute hit rate by user rating in the hold out movie\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "hit_rate_by_rating = get_hit_rate_by_rating(user_list, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7aeaae-e6ec-44a2-9ae1-62fbcc759f6c",
   "metadata": {},
   "source": [
    "Hit rate **higher for positive scores** in the hold-out movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "73f8c2b1-37fc-429a-9dca-3599b933e42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For interval==(0, 50] hit rate==0.128\n",
      "For interval==(50, 100] hit rate==0.105\n",
      "For interval==(200, 20000] hit rate==0.121\n",
      "For interval==(100, 150] hit rate==0.091\n",
      "For interval==(150, 200] hit rate==0.126\n"
     ]
    }
   ],
   "source": [
    "# evaluate hit rate by number of ratings in the user training set\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "hit_rate_by_n_ratings = get_hit_rate_by_n_ratings(user_list, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd82800a-cd38-4452-9676-c531d5a7585c",
   "metadata": {},
   "source": [
    "**Hit rate decreases** for users with **n_ratings above 50**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5baf416-e9b8-4b69-9e6d-5bc580c5d8b4",
   "metadata": {},
   "source": [
    "#### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a7f56743-2da4-4886-b244-8427115f12bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha==0.0010 hit rate==0.096\n",
      "For alpha==0.0100 hit rate==0.080\n",
      "For alpha==0.1000 hit rate==0.102\n",
      "For alpha==1.0000 hit rate==0.058\n"
     ]
    }
   ],
   "source": [
    "# define range for alpha parameter\n",
    "param_range = [0.001, 0.01, 0.1, 1]\n",
    "# for different values of parameter alpha\n",
    "hit_rate_list = []\n",
    "for param in param_range:\n",
    "    # initialize classifier\n",
    "    bnb = BernoulliNB(alpha=param)\n",
    "    # compute the hit rate\n",
    "    hit_rate = get_hit_rate(user_list, clf=bnb)\n",
    "    # append hit rate to the hit_rate_list\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    # print results\n",
    "    print('For alpha=={:.4f} hit rate=={:.3f}'.format(param, hit_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1bacfc-a10a-4062-aded-e3d8868d9ce3",
   "metadata": {},
   "source": [
    "Parameter **alpha will be set as 0.1**\n",
    "\n",
    "**Hit rate of 10.2%** equal to 10% baseline of a random ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "430edff3-0ba0-422c-a553-f1d47a2ab520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rating==0 hit rate==0.103\n",
      "For rating==1 hit rate==0.099\n"
     ]
    }
   ],
   "source": [
    "# evalute hit rate by user rating in the hold out movie\n",
    "bnb = BernoulliNB(alpha=0.1)\n",
    "hit_rate_by_rating = get_hit_rate_by_rating(user_list, bnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0bead9-f33e-46c6-b38e-d706cd1040a4",
   "metadata": {},
   "source": [
    "**Hit rate similar** for positive and negative scores in the hold-out movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4f619d49-bc65-4c02-9b6e-c7c2ecda27fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For interval==(0, 50] hit rate==0.089\n",
      "For interval==(50, 100] hit rate==0.092\n",
      "For interval==(200, 20000] hit rate==0.086\n",
      "For interval==(100, 150] hit rate==0.099\n",
      "For interval==(150, 200] hit rate==0.102\n"
     ]
    }
   ],
   "source": [
    "# evaluate hit rate by number of ratings in the user training set\n",
    "bnb = BernoulliNB(alpha=0.1)\n",
    "hit_rate_by_n_ratings = get_hit_rate_by_n_ratings(user_list, bnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ce4340-50a4-4513-b098-ad63c16c5f6b",
   "metadata": {},
   "source": [
    "**Hit rate usually increases** as n_ratings increase, except for the more than 200 segment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1567233-0683-41e3-9902-4ad033b9d84b",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "816ea48c-7120-4430-8ce3-a00163141bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C==0.001 hit rate==0.122\n",
      "For C==0.010 hit rate==0.116\n",
      "For C==0.100 hit rate==0.128\n",
      "For C==1.000 hit rate==0.124\n"
     ]
    }
   ],
   "source": [
    "# define range for C parameter\n",
    "param_range = [0.001, 0.01, 0.1, 1]\n",
    "# for different values of C parameter\n",
    "hit_rate_list = []\n",
    "for param in param_range:\n",
    "    # initialize classifier\n",
    "    lr = LogisticRegression(C=param)\n",
    "    # compute the hit rate\n",
    "    hit_rate = get_hit_rate(user_list, clf=lr)\n",
    "    # append hit rate to the hit_rate_list\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    # print results\n",
    "    print('For C=={:.3f} hit rate=={:.3f}'.format(param, hit_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9f2baa-9407-42fc-864e-59dfa9030d7b",
   "metadata": {},
   "source": [
    "Parameter **C will be set as 0.1**\n",
    "\n",
    "**Hit rate of 12.8%** slightly better than 10% baseline of a random ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6d3d5e1b-8940-4a75-ac54-48c94b3277a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rating==0 hit rate==0.131\n",
      "For rating==1 hit rate==0.139\n"
     ]
    }
   ],
   "source": [
    "# evalute hit rate by user rating in the hold out movie\n",
    "lr = LogisticRegression(C=0.1)\n",
    "hit_rate_by_rating = get_hit_rate_by_rating(user_list, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a67ff7b-f955-436b-8172-9236f858fa5f",
   "metadata": {},
   "source": [
    "Hit rate **higher for positive scores** in the hold-out movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a87f9c58-ecd9-451c-af21-7948f4a401ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For interval==(0, 50] hit rate==0.111\n",
      "For interval==(50, 100] hit rate==0.134\n",
      "For interval==(200, 20000] hit rate==0.134\n",
      "For interval==(100, 150] hit rate==0.144\n",
      "For interval==(150, 200] hit rate==0.114\n"
     ]
    }
   ],
   "source": [
    "# evaluate hit rate by number of ratings in the user training set\n",
    "lr = LogisticRegression(C=0.1)\n",
    "hit_rate_by_n_ratings = get_hit_rate_by_n_ratings(user_list, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7193252-ca4c-444b-9aea-b6183aa03102",
   "metadata": {},
   "source": [
    "**Hit rate usually increases** as n_ratings increase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a5676-8af8-4895-ae38-0326aed15db9",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "898af55b-b539-4793-9a1c-659981c071c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C==0.001 hit rate==0.126\n",
      "For C==0.010 hit rate==0.124\n",
      "For C==0.100 hit rate==0.156\n",
      "For C==1.000 hit rate==0.108\n",
      "For C==10.000 hit rate==0.130\n"
     ]
    }
   ],
   "source": [
    "# define range for C parameter\n",
    "param_range = [0.001, 0.01, 0.1, 1, 10]\n",
    "# for different values of C parameter\n",
    "hit_rate_list = []\n",
    "for param in param_range:\n",
    "    # initialize classifier\n",
    "    svm = SVC(C=param, kernel='rbf', probability=True)\n",
    "    # compute the hit rate\n",
    "    hit_rate = get_hit_rate(user_list, clf=svm)\n",
    "    # append hit rate to the hit_rate_list\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    # print results\n",
    "    print('For C=={:.3f} hit rate=={:.3f}'.format(param, hit_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45148387-135b-4ce9-9023-075918e760a7",
   "metadata": {},
   "source": [
    "Parameter **alpha will be set as 0.1**\n",
    "\n",
    "**Hit rate of 15.6%** slightly better than 10% baseline of a random ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b3a8a15c-08fe-4b28-b370-bb7aaed298da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rating==0 hit rate==0.149\n",
      "For rating==1 hit rate==0.129\n"
     ]
    }
   ],
   "source": [
    "# evalute hit rate by user rating in the hold out movie\n",
    "svm = SVC(C=0.1, kernel='rbf', probability=True)\n",
    "hit_rate_by_rating = get_hit_rate_by_rating(user_list, svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ee987-3795-4af7-a9cd-49e1e3822759",
   "metadata": {},
   "source": [
    "Hit rate **higher for negative scores** in the hold-out movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "91f727f0-9fea-4375-8aa6-59a4422aac09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For interval==(0, 50] hit rate==0.109\n",
      "For interval==(50, 100] hit rate==0.134\n",
      "For interval==(200, 20000] hit rate==0.142\n",
      "For interval==(100, 150] hit rate==0.163\n",
      "For interval==(150, 200] hit rate==0.143\n"
     ]
    }
   ],
   "source": [
    "# evaluate hit rate by number of ratings in the user training set\n",
    "svm = SVC(C=0.1, kernel='rbf', probability=True)\n",
    "hit_rate_by_n_ratings = get_hit_rate_by_n_ratings(user_list, svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f8e13-a290-4d99-9917-a11a2210a3c7",
   "metadata": {},
   "source": [
    "Hit rate **higher** for n_ratings **larger than 50**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ad0e34-b6e3-496b-b5a7-ac1146226a98",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "aeb2f3bc-7357-4d1a-9581-774eec0fc6a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C==  5 hit rate==0.122\n",
      "For C== 10 hit rate==0.120\n",
      "For C== 50 hit rate==0.138\n",
      "For C==100 hit rate==0.120\n"
     ]
    }
   ],
   "source": [
    "# define range for n_estimators parameter\n",
    "param_range = [5, 10, 50, 100]\n",
    "# for different values of n_estimators parameter\n",
    "hit_rate_list = []\n",
    "for param in param_range:\n",
    "    # initialize classifier\n",
    "    rfc = RandomForestClassifier(n_estimators=param, criterion='entropy')\n",
    "    # compute the hit rate\n",
    "    hit_rate = get_hit_rate(user_list, clf=rfc)\n",
    "    # append hit rate to the hit_rate_list\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    # print results\n",
    "    print('For n_estimators=={:3} hit rate=={:.3f}'.format(param, hit_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0413243-13f4-49d6-9e39-67a36bda02fe",
   "metadata": {},
   "source": [
    "Parameter **n_estimators will be set as 50**\n",
    "\n",
    "**Hit rate of 13.8%** slightly better than 10% baseline of a random ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "216ae5c8-a8ee-4df7-ac7d-e35ab3d6bab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rating==0 hit rate==0.112\n",
      "For rating==1 hit rate==0.128\n"
     ]
    }
   ],
   "source": [
    "# evalute hit rate by user rating in the hold out movie\n",
    "rfc = RandomForestClassifier(n_estimators=50, criterion='entropy')\n",
    "hit_rate_by_rating = get_hit_rate_by_rating(user_list, rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b6d2dc-cd68-4872-b346-cf704aee747f",
   "metadata": {},
   "source": [
    "Hit rate **higher for positive scores** in the hold-out movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d9bc9966-96da-4961-a048-ced15408c393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For interval==(0, 50] hit rate==0.128\n",
      "For interval==(50, 100] hit rate==0.135\n",
      "For interval==(200, 20000] hit rate==0.121\n",
      "For interval==(100, 150] hit rate==0.146\n",
      "For interval==(150, 200] hit rate==0.124\n"
     ]
    }
   ],
   "source": [
    "# evaluate hit rate by number of ratings in the user training set\n",
    "rfc = RandomForestClassifier(n_estimators=50, criterion='entropy')\n",
    "hit_rate_by_n_ratings = get_hit_rate_by_n_ratings(user_list, rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b377cff3-c5d2-4356-8548-b872e3fe7ce6",
   "metadata": {},
   "source": [
    "**Hit rate usually increases** as n_ratings increase"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
