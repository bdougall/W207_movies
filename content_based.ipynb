{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9533b06-7110-418e-9472-fc5b5117f953",
   "metadata": {},
   "source": [
    "### Step 1: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8394217b-7ec5-47b9-92ab-fc212d6c00a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d7dd9b-c232-4dc4-bba3-f3b3d4576d55",
   "metadata": {},
   "source": [
    "### Step 2: Define working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab05abd0-103d-4964-96ab-b799df715b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw_data = 'C:/users/lbros/documents/mids/w207/final_project/raw_data/'\n",
    "path_clean_data = 'C:/users/lbros/documents/mids/w207/final_project/clean_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826754a3-e66a-490a-9394-c965033b75a2",
   "metadata": {},
   "source": [
    "### Step 3: Load clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af236d2d-65bd-4909-8025-b53a7a472b0b",
   "metadata": {},
   "source": [
    "#### Split ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e3572a-528c-4b60-8958-770842618794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ratings dataframes\n",
    "dev_train = pd.read_csv(path_clean_data + 'dev_train.csv')\n",
    "dev_test = pd.read_csv(path_clean_data + 'dev_test.csv')\n",
    "test_train = pd.read_csv(path_clean_data + 'test_train.csv')\n",
    "test_test = pd.read_csv(path_clean_data + 'test_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9ed7d75-a2e1-414a-a2aa-5b5e6b453a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'Unnamed 0' column\n",
    "dev_train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "dev_test.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "test_train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "test_test.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ecbdef-1d61-4601-8c73-0f34ca00b808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes\n",
      "dev_train: (834600, 3)\n",
      "dev_test: (5000, 3)\n",
      "test_train: (17948251, 3)\n",
      "test_test: (107150, 3)\n"
     ]
    }
   ],
   "source": [
    "# print dataframes shapes\n",
    "print('Shapes')\n",
    "print('dev_train:', dev_train.shape)\n",
    "print('dev_test:', dev_test.shape)\n",
    "print('test_train:', test_train.shape)\n",
    "print('test_test:', test_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db0a4767-136b-4c42-9546-9eccfd51fe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['userId', 'imdb_id', 'rating'], dtype='object')\n",
      "Index(['userId', 'imdb_id', 'rating'], dtype='object')\n",
      "Index(['userId', 'imdb_id', 'rating'], dtype='object')\n",
      "Index(['userId', 'imdb_id', 'rating'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print dataframes columns\n",
    "print(dev_train.columns)\n",
    "print(dev_test.columns)\n",
    "print(test_train.columns)\n",
    "print(test_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6738b2-7106-4798-88ae-ebbc4764507b",
   "metadata": {},
   "source": [
    "#### Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33937f1e-11ba-44b4-815c-348797407cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load movies dataframe\n",
    "movies_df = pd.read_csv(path_clean_data + 'movies_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1b2fc61-5d5b-4357-bf17-24dd9bd8bd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated imdb_id:  546\n"
     ]
    }
   ],
   "source": [
    "# print remaining imdb_id duplicates (if any)\n",
    "print('Number of duplicated imdb_id: ', movies_df[movies_df['imdb_id'].duplicated()].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "808647ff-8f78-46a2-b394-4277819e3af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude remaining imdb_id duplicates\n",
    "movies_df = movies_df[~movies_df['imdb_id'].duplicated(keep='last')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a92f1af8-da50-45bb-b958-cdb87cb47634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set imdb_id as index\n",
    "movies_df.set_index('imdb_id', verify_integrity=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44445309-34b5-4d5f-8426-07c260c3ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove fields unnamed: 0, id, tagline, description, production_countries, production_companies\n",
    "movies_df = movies_df.drop(['Unnamed: 0', 'id', 'tagline', 'description', 'production_countries', 'production_companies'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44fbcf4b-a9ed-4a4e-9fdc-ca6cd56cdd48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29399, 173)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print dataframe shape\n",
    "movies_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e287c09-ab07-476e-b8c1-541cb3fd5899",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['adult', 'belongs_to_collection', 'budget', 'originally_english',\n",
       "       'overview', 'popularity', 'revenue', 'runtime', 'title', 'video',\n",
       "       ...\n",
       "       'zh', 'zu', 'canceled', 'in-production', 'planned', 'post-production',\n",
       "       'released', 'rumored', 'cast_names', 'crew_names'],\n",
       "      dtype='object', length=173)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print dataframe columns\n",
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d973a-0c48-4a18-b8cc-bc6777cd297f",
   "metadata": {},
   "source": [
    "### Step 4: Vectorize text fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4008eb35-3136-45e9-8914-805f89539194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies_df shape:  (29399, 769)\n"
     ]
    }
   ],
   "source": [
    "# create an instance of a TfidfVectorizer object for overview\n",
    "# set it to keep the top 200 most significant words in the overview column\n",
    "tfidf_overview = TfidfVectorizer(max_features=200)\n",
    "t_overview = tfidf_overview.fit_transform(movies_df.overview)\n",
    "\n",
    "# create a dataframe of the transformed top 200 overview features\n",
    "overview = pd.DataFrame(t_overview.todense()).add_prefix('overview_')\n",
    "\n",
    "# fill the NA values in the title column with unknown\n",
    "movies_df.title.fillna('unknown', inplace=True)\n",
    "\n",
    "# create an instance of a TfidfVectorizer object for title\n",
    "# set it to keep the top 200 most significant words in the title column\n",
    "tfidf_title = TfidfVectorizer(max_features=200)\n",
    "t_title = tfidf_title.fit_transform(movies_df.title)\n",
    "\n",
    "# create a dataframe of the transformed top 200 overview features\n",
    "title = pd.DataFrame(t_title.todense()).add_prefix('title_')\n",
    "\n",
    "# create an instance of a TfidfVectorizer object for cast names, keeping the 100 most significant cast names\n",
    "tfidf_cast = TfidfVectorizer(max_features=100)\n",
    "t_cast = tfidf_cast.fit_transform(movies_df.cast_names)\n",
    "\n",
    "# create a dataframe of the transformed top 100 cast name features\n",
    "cast = pd.DataFrame(t_cast.todense()).add_prefix('cast_')\n",
    "\n",
    "# create an instance of a TfidfVectorizer for crew names, keeping the 100 most significant crew names\n",
    "tfidf_crew = TfidfVectorizer(max_features=100)\n",
    "t_crew = tfidf_crew.fit_transform(movies_df.crew_names)\n",
    "\n",
    "# create a dataframe of the transformed top 100 crew name features\n",
    "crew = pd.DataFrame(t_crew.todense()).add_prefix('crew_')\n",
    "\n",
    "# concatenate these columns into a single dataframe\n",
    "text = pd.concat([overview, title, cast, crew], axis=1)\n",
    "\n",
    "# free-up memory deleting intermediate objects\n",
    "del overview\n",
    "del title\n",
    "del cast\n",
    "del crew\n",
    "\n",
    "# drop the text columns that have been converted to numeric scores from movies_df\n",
    "movies_df.drop(['overview', 'title', 'cast_names', 'crew_names'], axis=1, inplace=True)\n",
    "\n",
    "# add back to the movies_df the numeric representations of the original text columns\n",
    "movies_df = pd.concat([movies_df.reset_index(), text], axis=1).set_index('imdb_id')\n",
    "print('movies_df shape: ', movies_df.shape)\n",
    "\n",
    "# free-up memory deleting intermediate objects\n",
    "del text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6863c28-da46-45d2-a67f-437390bb4b0c",
   "metadata": {},
   "source": [
    "### Step 5: Normalize features (all between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eed62bf-ea38-4e1b-84e2-8df87a31d957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_rep shape:  (29399, 769)\n"
     ]
    }
   ],
   "source": [
    "# transform movies_df in a numpy array\n",
    "a = movies_df.iloc[:,0:].values\n",
    "\n",
    "# create an instance of a MinMaxScaler and fit it to the numeric data\n",
    "min_max_sc = MinMaxScaler()\n",
    "num_rep = min_max_sc.fit_transform(a)\n",
    "print('num_rep shape: ', num_rep.shape)\n",
    "\n",
    "# free-up memory deleting intermediate objects\n",
    "del a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517ceda4-6955-4e8e-87d2-01b95261f899",
   "metadata": {},
   "source": [
    "### Step 6: Reduce dimensionality using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be24991e-79ac-45e6-beb4-9c8e39646e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93781965-810d-41a5-a7fb-6f42aef43564",
   "metadata": {},
   "source": [
    "### Step 7: Test and tune hyperparameters for different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f2e761-89a1-4003-bd2d-05d2567eaeb4",
   "metadata": {},
   "source": [
    "#### Define auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d6e79c9-b640-42ec-9838-e26381c688f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clf(user_id, clf, train_ratings_data=dev_train, test_ratings_data=dev_test, movies_data=movies_df, num_rep=num_rep):\n",
    "    \n",
    "    '''Run a classifier for a single user and return the score'''\n",
    "    \n",
    "    # get movies and ratings from user training data\n",
    "    train_movies = train_ratings_data[train_ratings_data['userId']==user_id]['imdb_id']\n",
    "    train_ratings = train_ratings_data[train_ratings_data['userId']==user_id]['rating']\n",
    "    #print('User {} rated {} movies in training set.'.format(user_id, len(train_movies)))\n",
    "    #print('User {} gave {} positive ratings and {} negative ratings.'.format(user_id, (train_ratings==1).sum(), (train_ratings==0).sum()), '\\n')\n",
    "    \n",
    "    # get movie and rating for hold out user test data\n",
    "    hold_out_movie = test_ratings_data[test_ratings_data['userId']==user_id]['imdb_id']\n",
    "    hold_out_rating = test_ratings_data[test_ratings_data['userId']==user_id]['rating']\n",
    "    #print('User {} rated {} movie in the hold-out set.'.format(user_id, len(hold_out_movie)))\n",
    "    #print('User {} gave a {} rating for the hold-out movie.'.format(user_id, int(hold_out_rating)), '\\n')\n",
    "    \n",
    "    # complement test data with other 99 randomly selected movies\n",
    "    allowed_list = movies_data.loc[~movies_data.index.isin(train_movies.append(hold_out_movie))]\n",
    "    rd_movies = allowed_list.sample(n=99, replace=False).index.to_series()\n",
    "    test_movies = hold_out_movie.append(rd_movies)\n",
    "    \n",
    "    # extract X_train and X_test matrices\n",
    "    X_train = num_rep[[movies_data.index.get_loc(x) for x in train_movies], :]\n",
    "    #print('X_train shape:', X_train.shape)\n",
    "    X_test = num_rep[[movies_data.index.get_loc(x) for x in test_movies], :]\n",
    "    #print('X_test shape:', X_test.shape)\n",
    "    \n",
    "    # extrac y_train vector\n",
    "    y_train = train_ratings.values\n",
    "    #print('y_train shape:', y_train.shape, '\\n')\n",
    "    \n",
    "    # fit training data\n",
    "    clf.fit(X_train, y_train)\n",
    "    # compute probabilities for each class\n",
    "    proba = clf.predict_proba(X_test)\n",
    "    # compute the ranking for class==test_ratings\n",
    "    ranking = np.argsort(proba, axis=0)[:,clf.classes_[clf.classes_==int(hold_out_rating)]]\n",
    "    # apply a positive hit if test example ranked on top-10 in descending order\n",
    "    score = ranking[0] > 89\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "521f4068-08ef-4cd2-9314-0a0f805087f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_rate(user_list, clf, train_ratings_data=dev_train, test_ratings_data=dev_test, movies_data=movies_df, num_rep=num_rep):\n",
    "\n",
    "    '''Compute hit rate across diferent users'''\n",
    "    \n",
    "    hit_list = []\n",
    "    for user_id in user_list:\n",
    "        score = run_clf(user_id, clf=clf, train_ratings_data=train_ratings_data, test_ratings_data=test_ratings_data, \n",
    "                            movies_data=movies_data, num_rep=num_rep)\n",
    "        hit_list.append(bool(score))\n",
    "    return sum(hit_list) / len(hit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a350eb0c-ac9d-48e2-86a2-45ffd856618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_rate_by_rating(user_list, clf, train_ratings_data=dev_train, test_ratings_data=dev_test, movies_data=movies_df, num_rep=num_rep):\n",
    "    \n",
    "    '''Compute hit rate by user rating in the hold out movie'''\n",
    "    \n",
    "    # for different ratings in the hold out movie\n",
    "    ratings = [0, 1]\n",
    "    hit_rate_by_rating = []\n",
    "    for r in ratings:\n",
    "        # define the user_list as the subset of users who gave rate r in the hold out movie\n",
    "        user_list = test_ratings_data[test_ratings_data['rating']==r]['userId']\n",
    "        # compute the hit rate\n",
    "        hit_rate = get_hit_rate(user_list=user_list, clf=clf, train_ratings_data=train_ratings_data, test_ratings_data=test_ratings_data, \n",
    "                                movies_data=movies_df, num_rep=num_rep)\n",
    "        # append hit rate to the hit_rate_by_rating\n",
    "        hit_rate_by_rating.append(hit_rate)\n",
    "        # print results\n",
    "        print('For rating=={} hit rate=={:.3f}'.format(r, hit_rate))\n",
    "    \n",
    "    return hit_rate_by_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3923ad4-422f-4461-973f-2e3c351ceed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_rate_by_n_ratings(user_list, clf, train_ratings_data=dev_train, test_ratings_data=dev_test, movies_data=movies_df, num_rep=num_rep):\n",
    "    \n",
    "    '''Compute hit rate by number of ratings in the user training set'''\n",
    "    \n",
    "    # split users by number of ratings\n",
    "    bins = [0, 50, 100, 150, 200, 20000]\n",
    "    user_list_by_n_ratings = pd.cut(train_ratings_data.groupby('userId').count()['rating'], bins).reset_index('userId')\n",
    "    intervals = user_list_by_n_ratings['rating'].unique()\n",
    "    # for different intervals of number of ratings\n",
    "    hit_rate_by_n_ratings = []\n",
    "    for i in intervals:\n",
    "        # define the user_list as the subset of users within the interval\n",
    "        user_list = user_list_by_n_ratings[user_list_by_n_ratings['rating']==i]['userId']\n",
    "        # compute the hit rate\n",
    "        hit_rate = get_hit_rate(user_list=user_list, clf=clf, train_ratings_data=train_ratings_data, test_ratings_data=test_ratings_data, \n",
    "                                movies_data=movies_df, num_rep=num_rep)\n",
    "        # append hit rate to the hit_rate_by_n_ratings\n",
    "        hit_rate_by_n_ratings.append(hit_rate)\n",
    "        # print results\n",
    "        print('For interval=={} hit rate=={:.3f}'.format(i, hit_rate))\n",
    "        \n",
    "    return hit_rate_by_n_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66d5de2a-329c-424d-a6fe-2fa9479f7aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gmm(user_id, n_components, train_ratings_data=dev_train, test_ratings_data=dev_test, movies_data=movies_df, num_rep=num_rep):\n",
    "    \n",
    "    '''Fit two GMMs, one for the positive and other for the negative examples, and use\n",
    "    the weighted log probabilities to compute the ranking and return the score'''\n",
    "    \n",
    "    # get movies and ratings from user training data\n",
    "    train_movies = train_ratings_data[train_ratings_data['userId']==user_id]['imdb_id']\n",
    "    train_ratings = train_ratings_data[train_ratings_data['userId']==user_id]['rating']\n",
    "    #print('User {} rated {} movies in training set.'.format(user_id, len(train_movies)))\n",
    "    #print('User {} gave {} positive ratings and {} negative ratings.'.format(user_id, (train_ratings==1).sum(), (train_ratings==0).sum()), '\\n')\n",
    "    \n",
    "    # get movie and rating for hold out user test data\n",
    "    hold_out_movie = test_ratings_data[test_ratings_data['userId']==user_id]['imdb_id']\n",
    "    hold_out_rating = test_ratings_data[test_ratings_data['userId']==user_id]['rating']\n",
    "    #print('User {} rated {} movie in the hold-out set.'.format(user_id, len(hold_out_movie)))\n",
    "    #print('User {} gave a {} rating for the hold-out movie.'.format(user_id, int(hold_out_rating)), '\\n')\n",
    "    \n",
    "    # complement test data with other 99 randomly selected movies\n",
    "    allowed_list = movies_data.loc[~movies_data.index.isin(train_movies.append(hold_out_movie))]\n",
    "    rd_movies = allowed_list.sample(n=99, replace=False).index.to_series()\n",
    "    test_movies = hold_out_movie.append(rd_movies)\n",
    "    \n",
    "    # extract X_train and X_test matrices\n",
    "    X_train = num_rep[[movies_data.index.get_loc(x) for x in train_movies], :]\n",
    "    #print('X_train shape:', X_train.shape)\n",
    "    X_test = num_rep[[movies_data.index.get_loc(x) for x in test_movies], :]\n",
    "    #print('X_test shape:', X_test.shape)\n",
    "    \n",
    "    # extrac y_train vector\n",
    "    y_train = train_ratings.values\n",
    "    #print('y_train shape:', y_train.shape, '\\n')\n",
    "    \n",
    "    # fit two GMMs, one for the positive labels and one for the negative labels\n",
    "    gmm_0 = GaussianMixture(n_components=n_components, covariance_type='full', random_state=100)\n",
    "    gmm_0.fit(X_train[y_train==0])\n",
    "    gmm_1 = GaussianMixture(n_components=n_components, covariance_type='full', random_state=100)\n",
    "    gmm_1.fit(X_train[y_train==1])\n",
    "    \n",
    "    # compute the weighted log probabilities for each test example in both models\n",
    "    log_prob_0 = gmm_0.score_samples(X_test)\n",
    "    log_prob_1 = gmm_1.score_samples(X_test)\n",
    "    proba = np.vstack((log_prob_0, log_prob_1)).T\n",
    "    \n",
    "    # compute the ranking for class==test_ratings\n",
    "    ranking = np.argsort(proba, axis=0)[:,int(hold_out_rating)]\n",
    "    # apply a positive hit if test example ranked on top-10 in descending order\n",
    "    score = ranking[0] > 89\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dacaff57-b04c-4e07-93c1-4f3e0a52f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_rate_gmm(user_list, n_components, train_ratings_data=dev_train, test_ratings_data=dev_test, movies_data=movies_df, num_rep=num_rep):\n",
    "\n",
    "    '''Compute hit rate across diferent users for GMM'''\n",
    "    \n",
    "    hit_list = []\n",
    "    for user_id in user_list:\n",
    "        score = run_gmm(user_id, n_components=n_components, train_ratings_data=train_ratings_data, test_ratings_data=test_ratings_data, \n",
    "                            movies_data=movies_data, num_rep=num_rep)\n",
    "        hit_list.append(bool(score))\n",
    "    return sum(hit_list) / len(hit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c3fc18d-eba2-4e09-99a4-20ad0ce48a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cosim(user_id, train_ratings_data=dev_train, test_ratings_data=dev_test, movies_data=movies_df, num_rep=num_rep):\n",
    "    \n",
    "    '''Compute two cosine similarity distances for each example in the test set, one against the positive examples in the training\n",
    "    set and other against the negative examples, and use the distances to compute the ranking and return the score'''\n",
    "    \n",
    "    # get movies and ratings from user training data\n",
    "    train_movies = train_ratings_data[train_ratings_data['userId']==user_id]['imdb_id']\n",
    "    train_ratings = train_ratings_data[train_ratings_data['userId']==user_id]['rating']\n",
    "    #print('User {} rated {} movies in training set.'.format(user_id, len(train_movies)))\n",
    "    #print('User {} gave {} positive ratings and {} negative ratings.'.format(user_id, (train_ratings==1).sum(), (train_ratings==0).sum()), '\\n')\n",
    "    \n",
    "    # get movie and rating for hold out user test data\n",
    "    hold_out_movie = test_ratings_data[test_ratings_data['userId']==user_id]['imdb_id']\n",
    "    hold_out_rating = test_ratings_data[test_ratings_data['userId']==user_id]['rating']\n",
    "    #print('User {} rated {} movie in the hold-out set.'.format(user_id, len(hold_out_movie)))\n",
    "    #print('User {} gave a {} rating for the hold-out movie.'.format(user_id, int(hold_out_rating)), '\\n')\n",
    "    \n",
    "    # complement test data with other 99 randomly selected movies\n",
    "    allowed_list = movies_data.loc[~movies_data.index.isin(train_movies.append(hold_out_movie))]\n",
    "    rd_movies = allowed_list.sample(n=99, replace=False).index.to_series()\n",
    "    test_movies = hold_out_movie.append(rd_movies)\n",
    "    \n",
    "    # extract X_train and X_test matrices\n",
    "    X_train = num_rep[[movies_data.index.get_loc(x) for x in train_movies], :]\n",
    "    #print('X_train shape:', X_train.shape)\n",
    "    X_test = num_rep[[movies_data.index.get_loc(x) for x in test_movies], :]\n",
    "    #print('X_test shape:', X_test.shape)\n",
    "    \n",
    "    # extrac y_train vector\n",
    "    y_train = train_ratings.values\n",
    "    #print('y_train shape:', y_train.shape, '\\n')\n",
    "    \n",
    "    # compute the cosine similarities, one for the positive labels and one for the negative labels\n",
    "    cosim_0 = cosine_similarity(X_test, X_train[y_train==0]).sum(axis=1)\n",
    "    cosim_1 = cosine_similarity(X_test, X_train[y_train==1]).sum(axis=1)\n",
    "    distance = np.vstack((cosim_0, cosim_1)).T\n",
    "\n",
    "    # compute the ranking for class==test_ratings\n",
    "    ranking = np.argsort(distance, axis=0)[:,int(hold_out_rating)]\n",
    "    # apply a positive hit if test example ranked on top-10 in ascending order\n",
    "    score = ranking[0] < 10\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a6c68b8-adc3-4a05-960c-dad6088c86ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_rate_cosim(user_list, train_ratings_data=dev_train, test_ratings_data=dev_test, movies_data=movies_df, num_rep=num_rep):\n",
    "\n",
    "    '''Compute hit rate across diferent users for cosine similarity'''\n",
    "    \n",
    "    hit_list = []\n",
    "    for user_id in user_list:\n",
    "        score = run_cosim(user_id, train_ratings_data=train_ratings_data, test_ratings_data=test_ratings_data, \n",
    "                          movies_data=movies_data, num_rep=num_rep)\n",
    "        hit_list.append(bool(score))\n",
    "    return sum(hit_list) / len(hit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9f380c2-e388-420f-b0e4-f892d022a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_baseline(user_id, train_ratings_data=dev_train, test_ratings_data=dev_test, movies_data=movies_df, num_rep=num_rep):\n",
    "    \n",
    "    '''Run a random classifier as a baseline'''\n",
    "    \n",
    "    # get movies and ratings from user training data\n",
    "    train_movies = train_ratings_data[train_ratings_data['userId']==user_id]['imdb_id']\n",
    "    train_ratings = train_ratings_data[train_ratings_data['userId']==user_id]['rating']\n",
    "    #print('User {} rated {} movies in training set.'.format(user_id, len(train_movies)))\n",
    "    #print('User {} gave {} positive ratings and {} negative ratings.'.format(user_id, (train_ratings==1).sum(), (train_ratings==0).sum()), '\\n')\n",
    "    \n",
    "    # get movie and rating for hold out user test data\n",
    "    hold_out_movie = test_ratings_data[test_ratings_data['userId']==user_id]['imdb_id']\n",
    "    hold_out_rating = test_ratings_data[test_ratings_data['userId']==user_id]['rating']\n",
    "    #print('User {} rated {} movie in the hold-out set.'.format(user_id, len(hold_out_movie)))\n",
    "    #print('User {} gave a {} rating for the hold-out movie.'.format(user_id, int(hold_out_rating)), '\\n')\n",
    "    \n",
    "    # complement test data with other 99 randomly selected movies\n",
    "    allowed_list = movies_data.loc[~movies_data.index.isin(train_movies.append(hold_out_movie))]\n",
    "    rd_movies = allowed_list.sample(n=99, replace=False).index.to_series()\n",
    "    test_movies = hold_out_movie.append(rd_movies)\n",
    "    \n",
    "    # extract X_train and X_test matrices\n",
    "    X_train = num_rep[[movies_data.index.get_loc(x) for x in train_movies], :]\n",
    "    #print('X_train shape:', X_train.shape)\n",
    "    X_test = num_rep[[movies_data.index.get_loc(x) for x in test_movies], :]\n",
    "    #print('X_test shape:', X_test.shape)\n",
    "    \n",
    "    # extrac y_train vector\n",
    "    y_train = train_ratings.values\n",
    "    #print('y_train shape:', y_train.shape, '\\n')\n",
    "    \n",
    "    # assign random probabilities for each class\n",
    "    proba = np.random.uniform(low=0.0, high=1.0, size=100).reshape(100,1)\n",
    "    # compute the ranking for class==test_ratings\n",
    "    ranking = np.argsort(proba, axis=0)\n",
    "    # apply a positive hit if test example ranked on top-10 in descending order\n",
    "    score = ranking[0] > 89\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56bdfaa4-4f55-4bd4-98ea-8955e5ed50c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_rate_baseline(user_list, train_ratings_data=dev_train, test_ratings_data=dev_test, movies_data=movies_df, num_rep=num_rep):\n",
    "\n",
    "    '''Compute hit rate across diferent users for random baseline'''\n",
    "    \n",
    "    hit_list = []\n",
    "    for user_id in user_list:\n",
    "        score = run_baseline(user_id, train_ratings_data=train_ratings_data, test_ratings_data=test_ratings_data, \n",
    "                             movies_data=movies_data, num_rep=num_rep)\n",
    "        hit_list.append(bool(score))\n",
    "    return sum(hit_list) / len(hit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5c1a766-875f-4231-922a-5924ca466434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ensemble(user_id, train_ratings_data=dev_train, test_ratings_data=dev_test, movies_data=movies_df, num_rep=num_rep):\n",
    "    \n",
    "    '''Run all classifiers for a single user and compute the average probability before returning the score'''\n",
    "    \n",
    "    # get movies and ratings from user training data\n",
    "    train_movies = train_ratings_data[train_ratings_data['userId']==user_id]['imdb_id']\n",
    "    train_ratings = train_ratings_data[train_ratings_data['userId']==user_id]['rating']\n",
    "    #print('User {} rated {} movies in training set.'.format(user_id, len(train_movies)))\n",
    "    #print('User {} gave {} positive ratings and {} negative ratings.'.format(user_id, (train_ratings==1).sum(), (train_ratings==0).sum()), '\\n')\n",
    "    \n",
    "    # get movie and rating for hold out user test data\n",
    "    hold_out_movie = test_ratings_data[test_ratings_data['userId']==user_id]['imdb_id']\n",
    "    hold_out_rating = test_ratings_data[test_ratings_data['userId']==user_id]['rating']\n",
    "    #print('User {} rated {} movie in the hold-out set.'.format(user_id, len(hold_out_movie)))\n",
    "    #print('User {} gave a {} rating for the hold-out movie.'.format(user_id, int(hold_out_rating)), '\\n')\n",
    "    \n",
    "    # complement test data with other 99 randomly selected movies\n",
    "    allowed_list = movies_data.loc[~movies_data.index.isin(train_movies.append(hold_out_movie))]\n",
    "    rd_movies = allowed_list.sample(n=99, replace=False).index.to_series()\n",
    "    test_movies = hold_out_movie.append(rd_movies)\n",
    "    \n",
    "    # extract X_train and X_test matrices\n",
    "    X_train = num_rep[[movies_data.index.get_loc(x) for x in train_movies], :]\n",
    "    #print('X_train shape:', X_train.shape)\n",
    "    X_test = num_rep[[movies_data.index.get_loc(x) for x in test_movies], :]\n",
    "    #print('X_test shape:', X_test.shape)\n",
    "    \n",
    "    # extrac y_train vector\n",
    "    y_train = train_ratings.values\n",
    "    #print('y_train shape:', y_train.shape, '\\n')\n",
    "    \n",
    "    # initialize the models\n",
    "    bnb = BernoulliNB(alpha=0.001)\n",
    "    rfc = RandomForestClassifier(n_estimators=2, criterion='entropy')\n",
    "    svm = SVC(C=1.0, kernel='rbf', probability=True)\n",
    "    knn = KNeighborsClassifier(n_neighbors=10)\n",
    "    lr = LogisticRegression(C=0.0100)\n",
    "    gmm_0 = GaussianMixture(n_components=3, covariance_type='full', random_state=100)\n",
    "    gmm_1 = GaussianMixture(n_components=3, covariance_type='full', random_state=100)\n",
    "    \n",
    "    # fit training data\n",
    "    bnb.fit(X_train, y_train)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    svm.fit(X_train, y_train)\n",
    "    knn.fit(X_train, y_train)\n",
    "    lr.fit(X_train, y_train)\n",
    "    gmm_0.fit(X_train[y_train==0])\n",
    "    gmm_1.fit(X_train[y_train==1])\n",
    "    \n",
    "    # compute probabilities for each model for class==test_ratings\n",
    "    bnb_proba = bnb.predict_proba(X_test)[:,int(hold_out_rating)].reshape(100,1)\n",
    "    rfc_proba = rfc.predict_proba(X_test)[:,int(hold_out_rating)].reshape(100,1)\n",
    "    svm_proba = svm.predict_proba(X_test)[:,int(hold_out_rating)].reshape(100,1)\n",
    "    knn_proba = knn.predict_proba(X_test)[:,int(hold_out_rating)].reshape(100,1)\n",
    "    lr_proba = lr.predict_proba(X_test)[:,int(hold_out_rating)].reshape(100,1)\n",
    "    gmm_prob_0 = np.exp(gmm_0.score_samples(X_test))\n",
    "    gmm_prob_1 = np.exp(gmm_1.score_samples(X_test))\n",
    "    gmm_proba = np.vstack((gmm_prob_0, gmm_prob_1)).T[:,int(hold_out_rating)].reshape(100,1)\n",
    "    \n",
    "    # compute the average probabilities\n",
    "    proba = np.hstack((bnb_proba, rfc_proba, svm_proba, knn_proba, lr_proba, gmm_proba)).mean(axis=1)\n",
    "    \n",
    "    # compute the ranking\n",
    "    ranking = np.argsort(proba, axis=0)\n",
    "    # apply a positive hit if test example ranked on top-10 in descending order\n",
    "    score = ranking[0] > 89\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef246225-2c66-4554-841f-e08c96cd2604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_rate_ensemble(user_list, train_ratings_data=dev_train, test_ratings_data=dev_test, movies_data=movies_df, num_rep=num_rep):\n",
    "\n",
    "    '''Compute hit rate across diferent users for ensemble method'''\n",
    "    \n",
    "    hit_list = []\n",
    "    for user_id in user_list:\n",
    "        score = run_ensemble(user_id, train_ratings_data=train_ratings_data, test_ratings_data=test_ratings_data, \n",
    "                             movies_data=movies_data, num_rep=num_rep)\n",
    "        hit_list.append(bool(score))\n",
    "    return sum(hit_list) / len(hit_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287e6bfd-b520-4184-9e3d-458599f35836",
   "metadata": {},
   "source": [
    "#### Test different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "831fe004-7ab7-426e-b01c-e89d04054742",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 200\n",
    "clf_list = ['Base', 'Cosine Sim', 'BNB', 'RF', 'SVM', 'KNN', 'LR', 'GMM', 'Ensemble']\n",
    "clf_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df8719-7cbe-413f-912b-ff0b6281a392",
   "metadata": {},
   "source": [
    "#### Baseline (random classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b00672b7-9888-434d-8c05-c31b33f7f703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (random classifier)\n",
      "hit rate==0.090\n"
     ]
    }
   ],
   "source": [
    "# define user_list (random samples of 200 users from dev set)\n",
    "user_list = np.random.choice(dev_train['userId'].unique(), size=sample_size, replace=False)\n",
    "# compute the hit rate\n",
    "hit_rate = get_hit_rate_baseline(user_list)\n",
    "# print results\n",
    "print('Baseline (random classifier)')\n",
    "print('hit rate=={:.3f}'.format(hit_rate))\n",
    "# append best_score to clf_scores\n",
    "clf_scores.append(hit_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ae1fc6-a6f7-4c0a-ac52-1994f8786016",
   "metadata": {},
   "source": [
    "#### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14e05fc2-3371-443a-8bdc-aeb0d57b427b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity\n",
      "hit rate==0.105\n"
     ]
    }
   ],
   "source": [
    "# define user_list (random samples of 200 users from dev set)\n",
    "user_list = np.random.choice(dev_train['userId'].unique(), size=sample_size, replace=False)\n",
    "# compute the hit rate\n",
    "hit_rate = get_hit_rate_cosim(user_list)\n",
    "# print results\n",
    "print('Cosine similarity')\n",
    "print('hit rate=={:.3f}'.format(hit_rate))\n",
    "# append best_score to clf_scores\n",
    "clf_scores.append(hit_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5baf416-e9b8-4b69-9e6d-5bc580c5d8b4",
   "metadata": {},
   "source": [
    "#### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7f56743-2da4-4886-b244-8427115f12bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB\n",
      "For alpha==0.0001 hit rate==0.110\n",
      "For alpha==0.0010 hit rate==0.140\n",
      "For alpha==0.0100 hit rate==0.125\n",
      "For alpha==0.1000 hit rate==0.105\n",
      "For alpha==1.0000 hit rate==0.100\n",
      "For alpha==2.0000 hit rate==0.065\n",
      "--------------------------------------------------\n",
      "Best param: 0.0010\n",
      "Best hit rate: 0.140\n"
     ]
    }
   ],
   "source": [
    "# define range for alpha parameter\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1, 2]\n",
    "# for different values of parameter alpha\n",
    "hit_rate_list = []\n",
    "print('BernoulliNB')\n",
    "for param in param_range:\n",
    "    # define user_list (random samples of 200 users from dev set)\n",
    "    user_list = np.random.choice(dev_train['userId'].unique(), size=sample_size, replace=False)\n",
    "    # initialize classifier\n",
    "    bnb = BernoulliNB(alpha=param)\n",
    "    # compute the hit rate\n",
    "    hit_rate = get_hit_rate(user_list, clf=bnb)\n",
    "    # append hit rate to the hit_rate_list\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    # print results\n",
    "    print('For alpha=={:.4f} hit rate=={:.3f}'.format(param, hit_rate))\n",
    "print('-'*50)\n",
    "print('Best param: {:.4f}'.format(param_range[hit_rate_list.index(max(hit_rate_list))]))\n",
    "print('Best hit rate: {:.3f}'.format(max(hit_rate_list)))\n",
    "# append best_score to clf_scores\n",
    "clf_scores.append(max(hit_rate_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ad0e34-b6e3-496b-b5a7-ac1146226a98",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aeb2f3bc-7357-4d1a-9581-774eec0fc6a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "For n_estimators==  1 hit rate==0.090\n",
      "For n_estimators==  2 hit rate==0.150\n",
      "For n_estimators==  5 hit rate==0.120\n",
      "For n_estimators== 10 hit rate==0.095\n",
      "For n_estimators== 50 hit rate==0.115\n",
      "For n_estimators==100 hit rate==0.135\n",
      "--------------------------------------------------\n",
      "Best param:   2\n",
      "Best hit rate: 0.150\n"
     ]
    }
   ],
   "source": [
    "# define range for n_estimators parameter\n",
    "param_range = [1, 2, 5, 10, 50, 100]\n",
    "# for different values of n_estimators parameter\n",
    "hit_rate_list = []\n",
    "print('Random Forest')\n",
    "for param in param_range:\n",
    "    # define user_list (random samples of 200 users from dev set)\n",
    "    user_list = np.random.choice(dev_train['userId'].unique(), size=sample_size, replace=False)\n",
    "    # initialize classifier\n",
    "    rfc = RandomForestClassifier(n_estimators=param, criterion='entropy')\n",
    "    # compute the hit rate\n",
    "    hit_rate = get_hit_rate(user_list, clf=rfc)\n",
    "    # append hit rate to the hit_rate_list\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    # print results\n",
    "    print('For n_estimators=={:3} hit rate=={:.3f}'.format(param, hit_rate))\n",
    "print('-'*50)\n",
    "print('Best param: {:3}'.format(param_range[hit_rate_list.index(max(hit_rate_list))]))\n",
    "print('Best hit rate: {:.3f}'.format(max(hit_rate_list)))\n",
    "# append best_score to clf_scores\n",
    "clf_scores.append(max(hit_rate_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a5676-8af8-4895-ae38-0326aed15db9",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "898af55b-b539-4793-9a1c-659981c071c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "For C==0.001 hit rate==0.100\n",
      "For C==0.010 hit rate==0.090\n",
      "For C==0.100 hit rate==0.120\n",
      "For C==1.000 hit rate==0.145\n",
      "For C==10.000 hit rate==0.115\n",
      "--------------------------------------------------\n",
      "Best param: 1.000\n",
      "Best hit rate: 0.145\n"
     ]
    }
   ],
   "source": [
    "# define range for C parameter\n",
    "param_range = [0.001, 0.01, 0.1, 1, 10]\n",
    "# for different values of C parameter\n",
    "hit_rate_list = []\n",
    "print('SVM')\n",
    "for param in param_range:\n",
    "    # define user_list (random samples of 200 users from dev set)\n",
    "    user_list = np.random.choice(dev_train['userId'].unique(), size=sample_size, replace=False)\n",
    "    # initialize classifier\n",
    "    svm = SVC(C=param, kernel='rbf', probability=True)\n",
    "    # compute the hit rate\n",
    "    hit_rate = get_hit_rate(user_list, clf=svm)\n",
    "    # append hit rate to the hit_rate_list\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    # print results\n",
    "    print('For C=={:.3f} hit rate=={:.3f}'.format(param, hit_rate))\n",
    "print('-'*50)\n",
    "print('Best param: {:.3f}'.format(param_range[hit_rate_list.index(max(hit_rate_list))]))\n",
    "print('Best hit rate: {:.3f}'.format(max(hit_rate_list)))\n",
    "# append best_score to clf_scores\n",
    "clf_scores.append(max(hit_rate_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079dc5de-ee05-4a58-9d54-fa578fb82cd8",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c39cd46b-d104-408f-9298-7a9c5371b89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors\n",
      "For k== 5 hit rate==0.090\n",
      "For k==10 hit rate==0.125\n",
      "For k==15 hit rate==0.095\n",
      "For k==20 hit rate==0.105\n",
      "For k==25 hit rate==0.100\n",
      "--------------------------------------------------\n",
      "Best param: 10\n",
      "Best hit rate: 0.125\n"
     ]
    }
   ],
   "source": [
    "# define range for k (n_neighbors) parameter\n",
    "param_range = [5, 10, 15, 20, 25]\n",
    "# for different values of parameter k (n_beighbors)\n",
    "hit_rate_list = []\n",
    "print('K-Nearest Neighbors')\n",
    "for param in param_range:\n",
    "    # define user_list (random samples of 200 users from dev set)\n",
    "    user_list = np.random.choice(dev_train['userId'].unique(), size=sample_size, replace=False)\n",
    "    # initialize classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=param)\n",
    "    # compute the hit rate\n",
    "    hit_rate = get_hit_rate(user_list, clf=knn)\n",
    "    # append hit rate to the hit_rate_list\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    # print results\n",
    "    print('For k=={:2} hit rate=={:.3f}'.format(param, hit_rate))\n",
    "print('-'*50)\n",
    "print('Best param: {:2}'.format(param_range[hit_rate_list.index(max(hit_rate_list))]))\n",
    "print('Best hit rate: {:.3f}'.format(max(hit_rate_list)))\n",
    "# append best_score to clf_scores\n",
    "clf_scores.append(max(hit_rate_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1567233-0683-41e3-9902-4ad033b9d84b",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5ebaa78-36d0-4751-b15b-a2be40013ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "For C==0.0001 hit rate==0.110\n",
      "For C==0.0010 hit rate==0.070\n",
      "For C==0.0100 hit rate==0.135\n",
      "For C==0.1000 hit rate==0.060\n",
      "For C==1.0000 hit rate==0.105\n",
      "--------------------------------------------------\n",
      "Best param: 0.0100\n",
      "Best hit rate: 0.135\n"
     ]
    }
   ],
   "source": [
    "# define range for C parameter\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "# for different values of C parameter\n",
    "hit_rate_list = []\n",
    "print('Logistic Regression')\n",
    "for param in param_range:\n",
    "    # define user_list (random samples of 200 users from dev set)\n",
    "    user_list = np.random.choice(dev_train['userId'].unique(), size=sample_size, replace=False)\n",
    "    # initialize classifier\n",
    "    lr = LogisticRegression(C=param)\n",
    "    # compute the hit rate\n",
    "    hit_rate = get_hit_rate(user_list, clf=lr)\n",
    "    # append hit rate to the hit_rate_list\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    # print results\n",
    "    print('For C=={:.4f} hit rate=={:.3f}'.format(param, hit_rate))\n",
    "print('-'*50)\n",
    "print('Best param: {:.4f}'.format(param_range[hit_rate_list.index(max(hit_rate_list))]))\n",
    "print('Best hit rate: {:.3f}'.format(max(hit_rate_list)))\n",
    "# append best_score to clf_scores\n",
    "clf_scores.append(max(hit_rate_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4b8c3a-1a80-45b2-8651-2a9f223a8bef",
   "metadata": {},
   "source": [
    "#### Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d5593b6-146a-49a1-b0fe-4dc6b2d25133",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM\n",
      "For n_components==1 hit rate==0.065\n",
      "For n_components==2 hit rate==0.080\n",
      "For n_components==3 hit rate==0.145\n",
      "For n_components==4 hit rate==0.110\n",
      "For n_components==5 hit rate==0.105\n",
      "--------------------------------------------------\n",
      "Best param: 3\n",
      "Best hit rate: 0.145\n"
     ]
    }
   ],
   "source": [
    "# define range for n_components parameter\n",
    "param_range = [1, 2, 3, 4, 5]\n",
    "# for different values of n_components parameter\n",
    "hit_rate_list = []\n",
    "print('GMM')\n",
    "for param in param_range:\n",
    "    # define user_list (random samples of 200 users from dev set)\n",
    "    user_list = np.random.choice(dev_train['userId'].unique(), size=sample_size, replace=False)\n",
    "    # compute the hit rate\n",
    "    hit_rate = get_hit_rate_gmm(user_list, n_components=param)\n",
    "    # append hit rate to the hit_rate_list\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    # print results\n",
    "    print('For n_components=={} hit rate=={:.3f}'.format(param, hit_rate))\n",
    "print('-'*50)\n",
    "print('Best param: {}'.format(param_range[hit_rate_list.index(max(hit_rate_list))]))\n",
    "print('Best hit rate: {:.3f}'.format(max(hit_rate_list)))\n",
    "# append best_score to clf_scores\n",
    "clf_scores.append(max(hit_rate_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735b2400-dfb9-4515-a35e-c4c4ca280222",
   "metadata": {},
   "source": [
    "#### Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfc5cf69-f277-4758-8f98-e2fd613fd7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Learning\n",
      "hit rate==0.085\n"
     ]
    }
   ],
   "source": [
    "# define user_list (random samples of 200 users from dev set)\n",
    "user_list = np.random.choice(dev_train['userId'].unique(), size=sample_size, replace=False)\n",
    "# compute the hit rate\n",
    "hit_rate = get_hit_rate_ensemble(user_list)\n",
    "# print results\n",
    "print('Ensemble Learning')\n",
    "print('hit rate=={:.3f}'.format(hit_rate))\n",
    "# append best_score to clf_scores\n",
    "clf_scores.append(hit_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82f674f-7097-421c-bde9-56b0ce1939b8",
   "metadata": {},
   "source": [
    "#### Plot comparative results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9638bec3-02eb-418a-8044-6804764cf7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.bar(clf_list[1:], clf_scores[1:], alpha=0.5)\n",
    "ax.hlines(clf_scores[0], xmin=-0.5, xmax=7.5, color='black', linestyles='dashed', label='baseline')\n",
    "ax.set_ylabel('Hit Ratio')\n",
    "ax.set_ylim(0.0, 0.2)\n",
    "ax.set_title('Best Hit Ratio by Classifier')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
