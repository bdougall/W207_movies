{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9533b06-7110-418e-9472-fc5b5117f953",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8394217b-7ec5-47b9-92ab-fc212d6c00a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d7dd9b-c232-4dc4-bba3-f3b3d4576d55",
   "metadata": {},
   "source": [
    "### Define working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab05abd0-103d-4964-96ab-b799df715b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw_data = 'C:/users/lbros/documents/mids/w207/final_project/raw_data/'\n",
    "path_clean_data = 'C:/users/lbros/documents/mids/w207/final_project/clean_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826754a3-e66a-490a-9394-c965033b75a2",
   "metadata": {},
   "source": [
    "### Load clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af236d2d-65bd-4909-8025-b53a7a472b0b",
   "metadata": {},
   "source": [
    "#### Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e3572a-528c-4b60-8958-770842618794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ratings dataframe\n",
    "ratings_df = pd.read_csv(path_clean_data + 'ratings_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fb5105b-b03a-4d1d-b14b-46dfb7026f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter usable columns\n",
    "ratings_df = ratings_df[['userId', 'imdbId', 'rating', 'timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aee73638-86ba-4e17-a86f-9d2daf9efc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename imdbId\n",
    "ratings_df.columns = ['userId', 'imdb_id', 'rating', 'timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60ecbdef-1d61-4601-8c73-0f34ca00b808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22040570, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print dataframe shape\n",
    "ratings_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db0a4767-136b-4c42-9546-9eccfd51fe89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userId', 'imdb_id', 'rating', 'timestamp'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print dataframe columns\n",
    "ratings_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6738b2-7106-4798-88ae-ebbc4764507b",
   "metadata": {},
   "source": [
    "#### Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "33937f1e-11ba-44b4-815c-348797407cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load movies dataframe\n",
    "movies_df = pd.read_csv(path_clean_data + 'movies_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "808647ff-8f78-46a2-b394-4277819e3af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude imdb_id duplicates\n",
    "movies_df = movies_df[~movies_df['imdb_id'].duplicated(keep='last')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a92f1af8-da50-45bb-b958-cdb87cb47634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set imdb_id as index\n",
    "movies_df.set_index('imdb_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2e9a747c-23ff-4d50-9f13-f6f52ce6abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter usable columns\n",
    "movies_df = movies_df.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "44fbcf4b-a9ed-4a4e-9fdc-ca6cd56cdd48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29399, 177)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print dataframe shape\n",
    "movies_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7e287c09-ab07-476e-b8c1-541cb3fd5899",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['adult', 'belongs_to_collection', 'budget', 'originally_english',\n",
       "       'overview', 'popularity', 'production_companies',\n",
       "       'production_countries', 'revenue', 'runtime',\n",
       "       ...\n",
       "       'zu', 'canceled', 'in-production', 'planned', 'post-production',\n",
       "       'released', 'rumored', 'cast_names', 'crew_names', 'description'],\n",
       "      dtype='object', length=177)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print dataframe columns\n",
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92398618-6969-48ad-9800-79b6a9ea628a",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54689365-3210-48ea-bfb6-8e293265d76f",
   "metadata": {},
   "source": [
    "#### Split users into dev and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28fe172f-cfbf-42c3-b813-c5e6c826bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_split(ratings_df, dev_size=5000, random_state=100):\n",
    "    \n",
    "    '''Split users into development and test sets'''\n",
    "    \n",
    "    # randomly pick [dev_size] users\n",
    "    unique_users = ratings_df['userId'].unique()\n",
    "    dev = np.random.choice(unique_users, size=dev_size, replace=False)\n",
    "    # split users into dev and test based on picked users\n",
    "    dev_users = ratings_df[np.isin(ratings_df['userId'], dev)]\n",
    "    test_users = ratings_df[~np.isin(ratings_df['userId'], dev)]\n",
    "    \n",
    "    return dev_users, test_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a5c5589-d0f5-4a80-a326-a3983394dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply user_split to ratings_df\n",
    "dev_users, test_users = user_split(ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "599f2d32-3308-46ec-83a8-1cba93e8eeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development set has 5000 unique users and 841019 ratings in total.\n"
     ]
    }
   ],
   "source": [
    "print('Development set has {} unique users and {} ratings in total.'.format(len(dev_users['userId'].unique()), dev_users.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccedd9a8-b48e-4b4c-8869-387f04ad4b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set has 126880 unique users and 21199551 ratings in total.\n"
     ]
    }
   ],
   "source": [
    "print('Test set has {} unique users and {} ratings in total.'.format(len(test_users['userId'].unique()), test_users.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188e74d2-f583-4c65-8789-f29fc80a7ee6",
   "metadata": {},
   "source": [
    "#### Hold last rating by user for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d368a54-33fd-4ca4-88a4-ddd0e9b07837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hold_last_out(user_data):\n",
    "    \n",
    "    '''Split ratings by user into train and test sets using the hold\n",
    "    last out method. Test contains the last rated movie by user while\n",
    "    training contains all the other rated movies.\n",
    "    '''\n",
    "    \n",
    "    # find the indexes correspondent to maximum timestamp by user\n",
    "    idx_test = user_data.groupby('userId', sort=False).idxmax()['timestamp']\n",
    "    # filter test data with idx_test\n",
    "    test = user_data.loc[idx_test]\n",
    "    # drop idx_test to get train data\n",
    "    train = user_data.drop(idx_test, axis=0)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1589e36-26a8-479a-b92c-3c0f37282e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply hold_last_out to dev_users\n",
    "dev_train, dev_test = hold_last_out(dev_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b869989-c745-4e1a-b1b2-1b5a4fcb769d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev_train set has 5000 unique users and 836019 ratings in total.\n"
     ]
    }
   ],
   "source": [
    "print('Dev_train set has {} unique users and {} ratings in total.'.format(len(dev_train['userId'].unique()), dev_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ba2a6b8-717b-44e0-a992-860615a4b9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev_test set has 5000 unique users and 5000 ratings in total.\n"
     ]
    }
   ],
   "source": [
    "print('Dev_test set has {} unique users and {} ratings in total.'.format(len(dev_test['userId'].unique()), dev_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6e8ea4a-dee6-40e6-afcd-da93519d0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply hold_last_out to test_users\n",
    "test_train, test_test = hold_last_out(test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4547fabb-30c6-4285-8bc3-fc02d12aa1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_train set has 126880 unique users and 21072671 ratings in total.\n"
     ]
    }
   ],
   "source": [
    "print('Test_train set has {} unique users and {} ratings in total.'.format(len(test_train['userId'].unique()), test_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a8a9759-b7bd-4c77-8e18-2d7cc337e4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_test set has 126880 unique users and 126880 ratings in total.\n"
     ]
    }
   ],
   "source": [
    "print('Test_test set has {} unique users and {} ratings in total.'.format(len(test_test['userId'].unique()), test_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d973a-0c48-4a18-b8cc-bc6777cd297f",
   "metadata": {},
   "source": [
    "### Vectorize text fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8324f1a-c2e8-4b21-964c-7ab672f6d116",
   "metadata": {},
   "source": [
    "#### Start with movie description as a pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c57489ef-2352-4182-840c-d3f7e3646568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each movie was converted into 9506 word tokens.\n"
     ]
    }
   ],
   "source": [
    "# initiatize TfidVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "# fit_transform movie description\n",
    "word_vector = vectorizer.fit_transform(movies_df['description'])\n",
    "# print number of features\n",
    "print('Each movie was converted into {} word tokens.'.format(len(vectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93781965-810d-41a5-a7fb-6f42aef43564",
   "metadata": {},
   "source": [
    "### Test different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1d6e79c9-b640-42ec-9838-e26381c688f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clf(user_id, clf=knn, train_ratings_data=dev_train, test_ratings_data=dev_test, movies_data=movies_df, word_vector=word_vector):\n",
    "    \n",
    "    '''Run a classifier for a single user and return hit score'''\n",
    "    \n",
    "    # get movies and ratings from user training data\n",
    "    train_movies = train_ratings_data[train_ratings_data['userId']==user_id]['imdb_id']\n",
    "    train_ratings = train_ratings_data[train_ratings_data['userId']==user_id]['rating']\n",
    "    #print('User {} rated {} movies in training set.'.format(user_id, len(train_movies)))\n",
    "    #print('User {} gave {} positive ratings and {} negative ratings.'.format(user_id, (train_ratings==1).sum(), (train_ratings==0).sum()), '\\n')\n",
    "    \n",
    "    # get movie and rating for hold out user test data\n",
    "    hold_out_movie = test_ratings_data[test_ratings_data['userId']==user_id]['imdb_id']\n",
    "    hold_out_rating = test_ratings_data[test_ratings_data['userId']==user_id]['rating']\n",
    "    #print('User {} rated {} movie in the hold-out set.'.format(user_id, len(hold_out_movie)))\n",
    "    #print('User {} gave a {} rating for the hold-out movie.'.format(user_id, int(hold_out_rating)), '\\n')\n",
    "    \n",
    "    # complement test data with other 99 randomly selected movies\n",
    "    allowed_list = movies_data.loc[~movies_data.index.isin(train_movies.append(hold_out_movie))]\n",
    "    rd_movies = allowed_list.sample(n=99, replace=False).index.to_series()\n",
    "    test_movies = hold_out_movie.append(rd_movies)\n",
    "    \n",
    "    # extract X_train and X_test matrices\n",
    "    X_train = word_vector[[movies_data.index.get_loc(x) for x in train_movies], :]\n",
    "    #print('X_train shape:', X_train.shape)\n",
    "    X_test = word_vector[[movies_data.index.get_loc(x) for x in test_movies], :]\n",
    "    #print('X_test shape:', X_test.shape)\n",
    "    \n",
    "    # extrac y_train vector\n",
    "    y_train = train_ratings.values\n",
    "    #print('y_train shape:', y_train.shape, '\\n')\n",
    "    \n",
    "    # fit training data\n",
    "    clf.fit(X_train, y_train)\n",
    "    # compute probabilities for each class\n",
    "    proba = clf.predict_proba(X_test)\n",
    "    # compute the ranking for class==test_ratings\n",
    "    ranking = np.argsort(proba, axis=0)[:,clf.classes_[clf.classes_==int(hold_out_rating)]]\n",
    "    # apply a positive hit if test example ranked on top-10\n",
    "    hit_score = ranking[0] > 89\n",
    "    \n",
    "    return hit_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "521f4068-08ef-4cd2-9314-0a0f805087f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_rate(user_list, clf=knn, train_ratings_data=dev_train, test_ratings_data=dev_test, movies_data=movies_df, word_vector=word_vector):\n",
    "\n",
    "    '''Compute hit rate across diferent users'''\n",
    "    \n",
    "    hit_list = []\n",
    "    for user_id in user_list:\n",
    "        train_ratings = train_ratings_data[train_ratings_data['userId']==user_id]['rating']\n",
    "        #print('User {} rated {} movies in training set.'.format(user_id, len(train_ratings)))\n",
    "        #print('User {} gave {} positive ratings and {} negative ratings.'.format(user_id, (train_ratings==1).sum(), (train_ratings==0).sum()), '\\n')\n",
    "        if train_ratings.sum()==0 or train_ratings.sum()==len(train_ratings):\n",
    "            continue\n",
    "        else:\n",
    "            hit_score = run_clf(user_id, clf=clf, train_ratings_data=train_ratings_data, test_ratings_data=test_ratings_data, movies_data=movies_data, word_vector=word_vector)\n",
    "            hit_list.append(bool(hit_score))\n",
    "    return sum(hit_list) / len(hit_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079dc5de-ee05-4a58-9d54-fa578fb82cd8",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "c39cd46b-d104-408f-9298-7a9c5371b89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12073806658644204"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_list = dev_train['userId'].unique()\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "get_hit_rate(user_list, clf=knn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
